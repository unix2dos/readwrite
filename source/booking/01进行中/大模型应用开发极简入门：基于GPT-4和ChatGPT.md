---
doc_type: weread-highlights-reviews
bookId: "3300090305"
author: 奥利维耶·卡埃朗  【法】玛丽-艾丽斯·布莱特
cover: https://cdn.weread.qq.com/weread/cover/44/cpplatform_uzfvcz8q85gdzbaqvchudt/t7_cpplatform_uzfvcz8q85gdzbaqvchudt1709868767.jpg
reviewCount: 0
noteCount: 12
readingStatus: 在读
progress: 31%
totalReadDay: 2
readingTime: 0小时23分钟
readingDate: 2024-03-15
isbn: 9787115636409
title: 《大模型应用开发极简入门：基于GPT-4和ChatGPT》
date: 2024-03-16

---

![ 大模型应用开发极简入门：基于GPT-4和ChatGPT|200](https://cdn.weread.qq.com/weread/cover/44/cpplatform_uzfvcz8q85gdzbaqvchudt/t7_cpplatform_uzfvcz8q85gdzbaqvchudt1709868767.jpg)


## 推荐序三 人人都要学会和AI相处


- 📌 我遇到一个非常奇怪的现象：我开设的《AI大模型全栈工程师》课程，涌入了很多不懂编程的朋友。他们无视标题里的“工程师”三个字，无视我在报课须知里列出的“会编程”的明确要求，还是报名了。经过与这些朋友沟通，我了解到他们是因为对AI时代的憧憬和焦虑，“有病乱投医”，买了这门并不十分适合他们的课。 
    - ⏱ 2024-03-15 23:16:47 
### 1.1 LLM概述


- 📌 LLM的发展可以追溯到几年前。它始于简单的语言模型，如n-gram模型。n-gram模型通过使用词频来根据前面的词预测句子中的下一个词，其预测结果是在训练文本中紧随前面的词出现的频率最高的词。虽然这种方法提供了不错的着手点，但是n-gram模型在理解上下文和语法方面仍需改进，因为它有时会生成不连贯的文本。 
    - ⏱ 2024-03-15 23:21:36 

- 📌 当GPT模型收到一段提示词之后，它首先将输入拆分成标记(token)。这些标记代表单词、单词的一部分、空格或标点符号。比如，在前面的例子中，提示词可以被拆分成［The, wea, ther, is, nice, today,,, so, I, de, ci, ded, to］。 
    - ⏱ 2024-03-15 23:28:02 

- 📌 “今天天气很好，所以我决定”之后，下一个最佳标记可能是“去”。
接下来重复此过程，但现在上下文变为“今天天气很好，所以我决定去”，之前预测的标记“去”被添加到原始提示词中。这个过程会一直重复，直到形成一个完整的句子：“今天天气很好，所以我决定去散步。”这个过程依赖于LLM学习从大量文本数据中预测下一个最有可能出现的单词的能力。 
    - ⏱ 2024-03-15 23:28:50 
### 1.2 GPT模型简史：从GPT-1到GPT-4


- 📌 GPT-3比GPT-2大得多，它有1750亿个参数，这使其能够捕捉更复杂的模式。此外，GPT-3是在更广泛的数据集上进行训练的。这包括Common Crawl（它就像互联网档案馆，其中包含来自数十亿个网页的文本）和维基百科。这个训练数据集包括来自网站、书籍和文章的内容，使得GPT-3能够更深入地理解语言和上下文。因此，GPT-3在各种语言相关任务中都展示出更强的性能。此外，它在文本生成方面还展示出更强的连贯性和创造力。它甚至能够编写代码片段，如SQL查询，并执行其他智能任务。此外，GPT-3取消了微调步骤，而这在之前的GPT模型中是必需的。 
    - ⏱ 2024-03-16 09:37:32 

- 📌 我们可以看到，对于相同的输入，第一个模型无法回答问题（它给出的回答甚至很奇怪），而第二个模型可以回答问题。当然，使用标准的GPT-3模型也能够得到所需的回答，但需要应用特定的提示词设计和优化技术。这种技术被称为提示工程(prompt engineering)， 
    - ⏱ 2024-03-16 09:38:39 

- 📌 OpenAI还提出了Codex模型，这是一个在数十亿行代码上进行了微调的GPT-3模型。正是它给GitHub Copilot这款自动化编程工具赋予了强大的能力，为使用Visual Studio Code、JetBrains甚至Neovim等许多文本编辑器的开发人员提供了帮助。然而，Codex模型在2023年3月被OpenAI弃用。相反，OpenAI建议用户从Codex切换到GPT-3.5 Turbo或GPT-4。与此同时，GitHub发布了基于GPT-4的Copilot X版本，其功能比之前的版本多得多。 
    - ⏱ 2024-03-16 09:41:28 

- 📌 ￼ 可以说，ChatGPT是由LLM驱动的应用程序，而不是真正的LLM。ChatGPT背后的LLM是GPT-3.5 Turbo。然而，OpenAI在发布说明中将ChatGPT称为“模型”。在本书中，除非操作代码，否则我们将ChatGPT用作通用术语，既指应用程序又指模型。在特指模型时，我们使用gpt-3.5-turbo。 
    - ⏱ 2024-03-16 09:42:39 
### 1.3 LLM用例和示例产品


- 📌 多邻国已经使用GPT-4为其产品添加了两个新功能：“角色扮演”和“解释我的答案”。这两个功能在名为Duolingo Max的新订阅级别中可用。借助这两个功能，多邻国填补了理论知识和语言应用之间的鸿沟。多亏了LLM，多邻国让语言学习者能够沉浸在真实世界的场景中。 
    - ⏱ 2024-03-16 13:02:19 
### 1.4 警惕AI幻觉：限制与考虑


- 📌 为了回答我们的问题，即2 + 2等于多少，GPT逐个生成每个标记。它之所以能正确回答，是因为它可能经常在训练文本中遇到2 + 2等于4。这并不能说明它会计算，只能说明它会补全文本而已。
￼ GPT很可能没有在其训练文本中见过太多次3695 × 123548。这就是它犯错的原因。你可以看到，即使犯了错，它对自己的错误输出也相当自信。因此，在应用程序中使用GPT时要特别小心。如果GPT犯错，那么你的应用程序可能会得到不一致的结果。 
    - ⏱ 2024-03-16 13:03:21 
### 2.1 基本概念


- 📌 提示词不仅适用于OpenAI API，而且是所有LLM的入口点。简单地说，提示词就是用户发送给模型的输入文本，用于指导模型执行特定任务。对于GPT-4和ChatGPT背后的模型，提示词具有聊天格式，输入消息和输出消息存储在列表中。 
    - ⏱ 2024-03-16 13:05:27 
### 2.2 OpenAI API提供的可用模型


- 📌 OpenAI提供了两个GPT-4模型￼：gpt-4的上下文窗口大小为8192个标记，gpt-4-32k的上下文窗口大小为32768个标记。32768个标记大约相当于24576个英语单词，即大约40页的上下文。
无论是GPT-3.5 Turbo还是GPT-4，都在持续更新。当提到gpt-3.5-turbo、gpt-3.5-turbo-16k、gpt-4和gpt-4-32k时，我们指的是这些模型的最新版本￼ 
    - ⏱ 2024-03-16 13:07:11 

# 读书笔记


# 本书评论
